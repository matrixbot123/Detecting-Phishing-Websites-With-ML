{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Some Housekeeping for the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Before you read ahead through the code ,try to understand this is my first full fledge project in machine learning and this feature feature_Extraction is no way elegant and also doesnt work sometimes \"you might see problems like 'Error trying to connect to sockets-closing sockets' thats is cause some url are ded from data set \""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "the data is downloaded and is being is being cut down for consistency and we have 5000 phishing and legit url each."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' for those people who dont have wget you can go to https://eternallybored.org/misc/wget/ and download a .exe file according to pc type(32x or 64x) and the put that wget.exe in the C:/windows/system32 -only for windows'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "''' for those people who dont have wget you can go to https://eternallybored.org/misc/wget/ and download a .exe file according to pc type(32x or 64x) and the put that wget.exe in the C:/windows/system32 -only for windows'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "--2021-02-11 00:01:36--  http://data.phishtank.com/data/online-valid.csv\nResolving data.phishtank.com (data.phishtank.com)... 104.16.101.75, 104.17.177.85\nConnecting to data.phishtank.com (data.phishtank.com)|104.16.101.75|:80... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: https://data.phishtank.com/data/online-valid.csv [following]\n--2021-02-11 00:01:36--  https://data.phishtank.com/data/online-valid.csv\nConnecting to data.phishtank.com (data.phishtank.com)|104.16.101.75|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://d1750zhbc38ec0.cloudfront.net/datadumps/verified_online.csv?Expires=1612981905&Signature=LuE3w8Lg8V-cPw-3yBtcEm2ohIqCK9uERSoNrjGwu99FMb5FJ2htNFU6wr6hHM3JwBSWs5q~D3GEfCwUUz43mOJ-vAgP8XvB-jU5fecbWk6g0eOi3VXq6BI8LnyJPdqIVTT7FwX6wU~RjZT2ClkyotL0tEmaS8bL0CmHC45qXiBZoMjVp9DH9AU3Q~tdwOdHe3I3edA5cTCIfRFmwn0-TCCHqAT0mOIpJ1NDaTSE-gOUOokTYECF7eAEsL12GXJL8V00i8g7kssO9OINqwMY~o0BgFGWosONcxr7I7eidu8IHQgnhfToyx2HoSjSEOK2Gs4G0o7AJsKu9pMQBY7SBA__&Key-Pair-Id=APKAILB45UG3RB4CSOJA [following]\n--2021-02-11 00:01:36--  https://d1750zhbc38ec0.cloudfront.net/datadumps/verified_online.csv?Expires=1612981905&Signature=LuE3w8Lg8V-cPw-3yBtcEm2ohIqCK9uERSoNrjGwu99FMb5FJ2htNFU6wr6hHM3JwBSWs5q~D3GEfCwUUz43mOJ-vAgP8XvB-jU5fecbWk6g0eOi3VXq6BI8LnyJPdqIVTT7FwX6wU~RjZT2ClkyotL0tEmaS8bL0CmHC45qXiBZoMjVp9DH9AU3Q~tdwOdHe3I3edA5cTCIfRFmwn0-TCCHqAT0mOIpJ1NDaTSE-gOUOokTYECF7eAEsL12GXJL8V00i8g7kssO9OINqwMY~o0BgFGWosONcxr7I7eidu8IHQgnhfToyx2HoSjSEOK2Gs4G0o7AJsKu9pMQBY7SBA__&Key-Pair-Id=APKAILB45UG3RB4CSOJA\nResolving d1750zhbc38ec0.cloudfront.net (d1750zhbc38ec0.cloudfront.net)... 52.84.90.29, 52.84.90.214, 52.84.90.147, ...\nConnecting to d1750zhbc38ec0.cloudfront.net (d1750zhbc38ec0.cloudfront.net)|52.84.90.29|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2366445 (2.3M) [text/csv]\nSaving to: 'online-valid.csv'\n\n     0K .......... .......... .......... .......... ..........  2%  288K 8s\n    50K .......... .......... .......... .......... ..........  4%  427K 6s\n   100K .......... .......... .......... .......... ..........  6%  512K 6s\n   150K .......... .......... .......... .......... ..........  8%  440K 5s\n   200K .......... .......... .......... .......... .......... 10%  490K 5s\n   250K .......... .......... .......... .......... .......... 12% 1.88M 4s\n   300K .......... .......... .......... .......... .......... 15% 1.60M 4s\n   350K .......... .......... .......... .......... .......... 17% 1.07M 3s\n   400K .......... .......... .......... .......... .......... 19%  881K 3s\n   450K .......... .......... .......... .......... .......... 21% 1.87M 3s\n   500K .......... .......... .......... .......... .......... 23% 2.23M 3s\n   550K .......... .......... .......... .......... .......... 25% 2.23M 2s\n   600K .......... .......... .......... .......... .......... 28% 3.12M 2s\n   650K .......... .......... .......... .......... .......... 30% 3.76M 2s\n   700K .......... .......... .......... .......... .......... 32% 2.28M 2s\n   750K .......... .......... .......... .......... .......... 34% 1.96M 2s\n   800K .......... .......... .......... .......... .......... 36% 3.72M 2s\n   850K .......... .......... .......... .......... .......... 38% 3.05M 1s\n   900K .......... .......... .......... .......... .......... 41% 4.31M 1s\n   950K .......... .......... .......... .......... .......... 43% 2.62M 1s\n  1000K .......... .......... .......... .......... .......... 45% 4.48M 1s\n  1050K .......... .......... .......... .......... .......... 47% 3.87M 1s\n  1100K .......... .......... .......... .......... .......... 49% 3.79M 1s\n  1150K .......... .......... .......... .......... .......... 51% 3.72M 1s\n  1200K .......... .......... .......... .......... .......... 54% 7.12M 1s\n  1250K .......... .......... .......... .......... .......... 56% 4.18M 1s\n  1300K .......... .......... .......... .......... .......... 58% 3.56M 1s\n  1350K .......... .......... .......... .......... .......... 60% 7.74M 1s\n  1400K .......... .......... .......... .......... .......... 62% 3.93M 1s\n  1450K .......... .......... .......... .......... .......... 64% 4.36M 1s\n  1500K .......... .......... .......... .......... .......... 67% 5.15M 1s\n  1550K .......... .......... .......... .......... .......... 69% 3.25M 0s\n  1600K .......... .......... .......... .......... .......... 71% 6.73M 0s\n  1650K .......... .......... .......... .......... .......... 73% 2.98M 0s\n  1700K .......... .......... .......... .......... .......... 75% 4.75M 0s\n  1750K .......... .......... .......... .......... .......... 77% 5.74M 0s\n  1800K .......... .......... .......... .......... .......... 80% 2.68M 0s\n  1850K .......... .......... .......... .......... .......... 82% 8.02M 0s\n  1900K .......... .......... .......... .......... .......... 84% 4.04M 0s\n  1950K .......... .......... .......... .......... .......... 86% 3.67M 0s\n  2000K .......... .......... .......... .......... .......... 88% 4.98M 0s\n  2050K .......... .......... .......... .......... .......... 90% 7.09M 0s\n  2100K .......... .......... .......... .......... .......... 93% 3.77M 0s\n  2150K .......... .......... .......... .......... .......... 95% 4.08M 0s\n  2200K .......... .......... .......... .......... .......... 97% 5.28M 0s\n  2250K .......... .......... .......... .......... .......... 99% 42.5K 0s\n  2300K ..........                                            100% 25.3M=2.4s\n\n2021-02-11 00:01:39 (954 KB/s) - 'online-valid.csv' saved [2366445/2366445]\n\n"
     ]
    }
   ],
   "source": [
    "!wget http://data.phishtank.com/data/online-valid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\LENOVO 2LIN\\Visual Studio Code\\git-project-folder\\Detecting-Phishing-Websites-With-ML\\data\\online-valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   phish_id                                                url  \\\n",
       "0   6962006  http://bancapor1nternet-netinterbankpe2.com/login   \n",
       "1   6961995  https://m-suchen-mobile.de/fahrzeuge/details.h...   \n",
       "2   6961993    https://iiaosdffff.easy.co/#0.35687929124938167   \n",
       "3   6961988  http://bancointerbank.personas-benvenido.com/l...   \n",
       "4   6961976  http://miserablereference.com/jlhodfdxqt.html?...   \n",
       "\n",
       "                                    phish_detail_url  \\\n",
       "0  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "1  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "2  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "3  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "4  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "\n",
       "             submission_time verified          verification_time online  \\\n",
       "0  2021-02-10T17:19:57+00:00      yes  2021-02-10T17:22:59+00:00    yes   \n",
       "1  2021-02-10T17:13:27+00:00      yes  2021-02-10T17:22:59+00:00    yes   \n",
       "2  2021-02-10T17:13:04+00:00      yes  2021-02-10T17:22:06+00:00    yes   \n",
       "3  2021-02-10T17:09:44+00:00      yes  2021-02-10T17:22:06+00:00    yes   \n",
       "4  2021-02-10T16:58:50+00:00      yes  2021-02-10T17:09:46+00:00    yes   \n",
       "\n",
       "       target  \n",
       "0       Other  \n",
       "1  eBay, Inc.  \n",
       "2       Other  \n",
       "3       Other  \n",
       "4       Other  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>phish_id</th>\n      <th>url</th>\n      <th>phish_detail_url</th>\n      <th>submission_time</th>\n      <th>verified</th>\n      <th>verification_time</th>\n      <th>online</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6962006</td>\n      <td>http://bancapor1nternet-netinterbankpe2.com/login</td>\n      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n      <td>2021-02-10T17:19:57+00:00</td>\n      <td>yes</td>\n      <td>2021-02-10T17:22:59+00:00</td>\n      <td>yes</td>\n      <td>Other</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6961995</td>\n      <td>https://m-suchen-mobile.de/fahrzeuge/details.h...</td>\n      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n      <td>2021-02-10T17:13:27+00:00</td>\n      <td>yes</td>\n      <td>2021-02-10T17:22:59+00:00</td>\n      <td>yes</td>\n      <td>eBay, Inc.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6961993</td>\n      <td>https://iiaosdffff.easy.co/#0.35687929124938167</td>\n      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n      <td>2021-02-10T17:13:04+00:00</td>\n      <td>yes</td>\n      <td>2021-02-10T17:22:06+00:00</td>\n      <td>yes</td>\n      <td>Other</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6961988</td>\n      <td>http://bancointerbank.personas-benvenido.com/l...</td>\n      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n      <td>2021-02-10T17:09:44+00:00</td>\n      <td>yes</td>\n      <td>2021-02-10T17:22:06+00:00</td>\n      <td>yes</td>\n      <td>Other</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6961976</td>\n      <td>http://miserablereference.com/jlhodfdxqt.html?...</td>\n      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n      <td>2021-02-10T16:58:50+00:00</td>\n      <td>yes</td>\n      <td>2021-02-10T17:09:46+00:00</td>\n      <td>yes</td>\n      <td>Other</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(11036, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   phish_id                                                url  \\\n",
       "0   6594543  https://produkte-kommunizieren.de/suchen/mobil...   \n",
       "1   6961090  https://lemosomc.com/gleed/gleeds_co_uksourced...   \n",
       "2   6961088  http://107.172.248.186/login.php?app-token=chg...   \n",
       "3   6952678  https://slokltd.us/signxls/?12=hk@milwaukeetoo...   \n",
       "4   5270040  http://electrocoolhvacr.com/control/163/163xff...   \n",
       "\n",
       "                                    phish_detail_url  \\\n",
       "0  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "1  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "2  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "3  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "4  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "\n",
       "             submission_time verified          verification_time online  \\\n",
       "0  2020-05-25T18:53:09+00:00      yes  2020-06-01T08:18:20+00:00    yes   \n",
       "1  2021-02-10T02:07:31+00:00      yes  2021-02-10T02:21:29+00:00    yes   \n",
       "2  2021-02-10T02:07:22+00:00      yes  2021-02-10T02:21:29+00:00    yes   \n",
       "3  2021-02-05T03:15:16+00:00      yes  2021-02-10T17:03:43+00:00    yes   \n",
       "4  2017-10-08T02:42:53+00:00      yes  2017-11-13T09:47:42+00:00    yes   \n",
       "\n",
       "       target  \n",
       "0  eBay, Inc.  \n",
       "1       Other  \n",
       "2       Other  \n",
       "3       Other  \n",
       "4       Other  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>phish_id</th>\n      <th>url</th>\n      <th>phish_detail_url</th>\n      <th>submission_time</th>\n      <th>verified</th>\n      <th>verification_time</th>\n      <th>online</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6594543</td>\n      <td>https://produkte-kommunizieren.de/suchen/mobil...</td>\n      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n      <td>2020-05-25T18:53:09+00:00</td>\n      <td>yes</td>\n      <td>2020-06-01T08:18:20+00:00</td>\n      <td>yes</td>\n      <td>eBay, Inc.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6961090</td>\n      <td>https://lemosomc.com/gleed/gleeds_co_uksourced...</td>\n      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n      <td>2021-02-10T02:07:31+00:00</td>\n      <td>yes</td>\n      <td>2021-02-10T02:21:29+00:00</td>\n      <td>yes</td>\n      <td>Other</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6961088</td>\n      <td>http://107.172.248.186/login.php?app-token=chg...</td>\n      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n      <td>2021-02-10T02:07:22+00:00</td>\n      <td>yes</td>\n      <td>2021-02-10T02:21:29+00:00</td>\n      <td>yes</td>\n      <td>Other</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6952678</td>\n      <td>https://slokltd.us/signxls/?12=hk@milwaukeetoo...</td>\n      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n      <td>2021-02-05T03:15:16+00:00</td>\n      <td>yes</td>\n      <td>2021-02-10T17:03:43+00:00</td>\n      <td>yes</td>\n      <td>Other</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5270040</td>\n      <td>http://electrocoolhvacr.com/control/163/163xff...</td>\n      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n      <td>2017-10-08T02:42:53+00:00</td>\n      <td>yes</td>\n      <td>2017-11-13T09:47:42+00:00</td>\n      <td>yes</td>\n      <td>Other</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "'''these sucker are the verified phishing websites which are verified by PhishTank and they are so kind to update it hourly . So I am taking a set of samples for feature extraction  ''' \n",
    "phishurl = data.sample(n = 5000,random_state = 1).copy()\n",
    "phishurl = phishurl.reset_index(drop = True)\n",
    "phishurl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5000, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "phishurl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                URLs\n",
       "0  http://1337x.to/torrent/1110018/Blackhat-2015-...\n",
       "1  http://1337x.to/torrent/1122940/Blackhat-2015-...\n",
       "2  http://1337x.to/torrent/1124395/Fast-and-Furio...\n",
       "3  http://1337x.to/torrent/1145504/Avengers-Age-o...\n",
       "4  http://1337x.to/torrent/1160078/Avengers-age-o..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URLs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://1337x.to/torrent/1110018/Blackhat-2015-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://1337x.to/torrent/1122940/Blackhat-2015-...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://1337x.to/torrent/1124395/Fast-and-Furio...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://1337x.to/torrent/1145504/Avengers-Age-o...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://1337x.to/torrent/1160078/Avengers-age-o...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "'''these are the legit websites which are collected by University of New Brunswick, https://www.unb.ca/cic/datasets/url-2016.html.So if you want to download and analyse the data the just go to the link .I have just downloaded the files and have put them in very useful folder \"data\" '''\n",
    "data1 = pd.read_csv(r\"C:\\Users\\LENOVO 2LIN\\Visual Studio Code\\git-project-folder\\Detecting-Phishing-Websites-With-ML\\data\\benign_list_big_final.csv\")\n",
    "data1.columns = ['URLs']\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                URLs\n",
       "0  http://graphicriver.net/search?date=this-month...\n",
       "1  http://ecnavi.jp/redirect/?url=http://www.cros...\n",
       "2  https://hubpages.com/signin?explain=follow+Hub...\n",
       "3  http://extratorrent.cc/torrent/4190536/AOMEI+B...\n",
       "4  http://icicibank.com/Personal-Banking/offers/o..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URLs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://graphicriver.net/search?date=this-month...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://ecnavi.jp/redirect/?url=http://www.cros...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://hubpages.com/signin?explain=follow+Hub...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://extratorrent.cc/torrent/4190536/AOMEI+B...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://icicibank.com/Personal-Banking/offers/o...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "legiturl = data1.sample(n = 5000, random_state = 12).copy()\n",
    "legiturl = legiturl.reset_index(drop=True)\n",
    "legiturl.head()"
   ]
  },
  {
   "source": [
    "# Feature Extraction for the Data\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'from here all the function are made is done according to the parameters paper available here http://eprints.hud.ac.uk/24330/6/MohammadPhishing14July2015.pdf and a copy will be in the repo '"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "'''from here all the function are made is done according to the parameters paper available here http://eprints.hud.ac.uk/24330/6/MohammadPhishing14July2015.pdf and a copy will be in the repo '''"
   ]
  },
  {
   "source": [
    "# Feature extraction's functions "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import urllib\n",
    "import urllib.request\n",
    "import ipaddress\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import whois\n",
    "from datetime import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDomain(url):\n",
    "  domain = urlparse(url).netloc\n",
    "  if re.match(r\"^www.\",domain):\n",
    "       domain = domain.replace(\"www.\",\"\")\n",
    "  return domain\n",
    "\n",
    "  # 2.Checks for IP address in URL (Have_IP)\n",
    "def havingIP(url):\n",
    "  try:\n",
    "    ipaddress.ip_address(url)\n",
    "    ip = 1\n",
    "  except:\n",
    "    ip = 0\n",
    "  return ip\n",
    "\n",
    "# 3.Checks the presence of @ in URL (Have_At)\n",
    "def haveAtSign(url):\n",
    "  if \"@\" in url:\n",
    "    at = 1    \n",
    "  else:\n",
    "    at = 0    \n",
    "  return at\n",
    "\n",
    "# 4.Finding the length of URL and categorizing (URL_Length)\n",
    "def getLength(url):\n",
    "  if len(url) < 54:\n",
    "    length = 0            \n",
    "  else:\n",
    "    length = 1            \n",
    "  return length\n",
    "\n",
    "# 5.Gives number of '/' in URL (URL_Depth)\n",
    "def getDepth(url):\n",
    "  s = urlparse(url).path.split('/')\n",
    "  depth = 0\n",
    "  for j in range(len(s)):\n",
    "    if len(s[j]) != 0:\n",
    "      depth = depth+1\n",
    "  return depth\n",
    "\n",
    "# 6.Checking for redirection '//' in the url (Redirection)\n",
    "def redirection(url):\n",
    "  pos = url.rfind('//')\n",
    "  if pos > 6:\n",
    "    if pos > 7:\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "# 7.Existence of “HTTPS” Token in the Domain Part of the URL (https_Domain)\n",
    "def httpDomain(url):\n",
    "  domain = urlparse(url).netloc\n",
    "  if 'https' in domain:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "# 8. Checking for Shortening Services in URL (Tiny_URL)\n",
    "def tinyURL(url):\n",
    "    #listing shortening services\n",
    "    shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
    "                        r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
    "                        r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
    "                        r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
    "                        r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
    "                        r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
    "                        r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
    "                        r\"tr\\.im|link\\.zip\\.net\"\n",
    "    match=re.search(shortening_services,url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# 9.Checking for Prefix or Suffix Separated by (-) in the Domain (Prefix/Suffix)\n",
    "def prefixSuffix(url):\n",
    "    if '-' in urlparse(url).netloc:\n",
    "        return 1            # phishing\n",
    "    else:\n",
    "        return 0            # legitimate\n",
    "\n",
    "\n",
    "# 11.DNS Record availability (DNS_Record) obtained in the featureExtraction function itself for convenience \n",
    "\n",
    "# 12.Web traffic (Web_Traffic)\n",
    "def web_traffic(url):\n",
    "  try:\n",
    "    #Filling the whitespaces in the URL if any\n",
    "    url = urllib.parse.quote(url)\n",
    "    rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\n",
    "        \"REACH\")['RANK']\n",
    "    rank = int(rank)\n",
    "  except TypeError:\n",
    "        return 1\n",
    "  if rank <100000:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "# 13.Survival time of domain: The difference between termination time and creation time (Domain_Age)  \n",
    "def domainAge(domain_name):\n",
    "  creation_date = domain_name.creation_date\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "    try:\n",
    "      creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if ((expiration_date is None) or (creation_date is None)):\n",
    "      return 1\n",
    "  elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n",
    "      return 1\n",
    "  else:\n",
    "    ageofdomain = abs((expiration_date - creation_date).days)\n",
    "    if ((ageofdomain/30) < 6):\n",
    "      age = 1\n",
    "    else:\n",
    "      age = 0\n",
    "  return age\n",
    "\n",
    "# 14.End time of domain: The difference between termination time and current time (Domain_End) \n",
    "def domainEnd(domain_name):\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if isinstance(expiration_date,str):\n",
    "    try:\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if (expiration_date is None):\n",
    "      return 1\n",
    "  elif (type(expiration_date) is list):\n",
    "      return 1\n",
    "  else:\n",
    "    today = datetime.now()\n",
    "    end = abs((expiration_date - today).days)\n",
    "    if ((end/30) < 6):\n",
    "      end = 0\n",
    "    else:\n",
    "      end = 1\n",
    "  return end\n",
    "\n",
    "# 15. IFrame Redirection (iFrame)\n",
    "def iframe(response):\n",
    "  if response == \"\":\n",
    "      return 1\n",
    "  else:\n",
    "      if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n",
    "          return 0\n",
    "      else:\n",
    "          return 1\n",
    "\n",
    "# 16.Checks the effect of mouse over on status bar (Mouse_Over)\n",
    "def mouseOver(response): \n",
    "  if response == \"\" :\n",
    "    return 1\n",
    "  else:\n",
    "    if re.findall(\"<script>.+onmouseover.+</script>\", response.text):\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "# 17.Checks the status of the right click attribute (Right_Click)\n",
    "def rightClick(response):\n",
    "  if response == \"\":\n",
    "    return 1\n",
    "  else:\n",
    "    if re.findall(r\"event.button ?== ?2\", response.text):\n",
    "      return 0\n",
    "    else:\n",
    "      return 1\n",
    "\n",
    "# 18.Checks the number of forwardings (Web_Forwards)    \n",
    "def forwarding(response):\n",
    "  if response == \"\":\n",
    "    return 1\n",
    "  else:\n",
    "    if len(response.history) <= 2:\n",
    "      return 0\n",
    "    else:\n",
    "      return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract features\n",
    "def feature_Extraction(url,label):\n",
    "\n",
    "  features = []\n",
    "  #Address bar based features (10)\n",
    "  features.append(getDomain(url))\n",
    "  features.append(havingIP(url))\n",
    "  features.append(haveAtSign(url))\n",
    "  features.append(getLength(url))\n",
    "  features.append(getDepth(url))\n",
    "  features.append(redirection(url))\n",
    "  features.append(httpDomain(url))\n",
    "  features.append(tinyURL(url))\n",
    "  features.append(prefixSuffix(url))\n",
    "  \n",
    "  #Domain based features (4)\n",
    "  dns = 0\n",
    "  try:\n",
    "    domain_name = whois.whois(urlparse(url).netloc)\n",
    "  except:\n",
    "    dns = 1\n",
    "\n",
    "  features.append(dns)\n",
    "  features.append(web_traffic(url))\n",
    "  features.append(1 if dns == 1 else domainAge(domain_name))\n",
    "  features.append(1 if dns == 1 else domainEnd(domain_name))\n",
    "  \n",
    "  # HTML & Javascript based features (4)\n",
    "  try:\n",
    "    response = requests.get(url)\n",
    "  except:\n",
    "    response = \"\"\n",
    "  features.append(iframe(response))\n",
    "  features.append(mouseOver(response))\n",
    "  features.append(rightClick(response))\n",
    "  features.append(forwarding(response))\n",
    "  features.append(label)\n",
    "  \n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Domain', 'Have_IP', 'Have_At', 'URL_Length', 'URL_Depth','Redirection', \n",
    "                      'https_Domain', 'TinyURL', 'Prefix/Suffix', 'DNS_Record', 'Web_Traffic', \n",
    "                      'Domain_Age', 'Domain_End', 'iFrame', 'Mouse_Over','Right_Click', 'Web_Forwards', 'Label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "Error trying to connect to socket: closing socket\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Error trying to connect to socket: closing socket\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Error trying to connect to socket: closing socket\n",
      "26\n",
      "Error trying to connect to socket: closing socket\n",
      "27\n",
      "Error trying to connect to socket: closing socket\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "Error trying to connect to socket: closing socket\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "Error trying to connect to socket: closing socket\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "Error trying to connect to socket: closing socket\n",
      "71\n",
      "72\n",
      "Error trying to connect to socket: closing socket\n",
      "73\n",
      "Error trying to connect to socket: closing socket\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "Error trying to connect to socket: closing socket\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "Error trying to connect to socket: closing socket\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "Error trying to connect to socket: closing socket\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "Error trying to connect to socket: closing socket\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Extracting the feautres & storing them in a list\n",
    "\n",
    "legit_features = []\n",
    "label = 0\n",
    "\n",
    "for i in range(0, 100):\n",
    "  url = legiturl['URLs'][i]\n",
    "  print(i)\n",
    "  legit_features.append(feature_Extraction(url,label))\n",
    "  \n",
    "#converting the list to dataframe\n",
    "\n",
    "legitimate = pd.DataFrame(legit_features, columns= feature_names)\n",
    "legitimate.head()\n",
    "\n",
    "# Storing the extracted legitimate URLs fatures to csv file\n",
    "legitimate.to_csv('legit_features.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Error trying to connect to socket: closing socket\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "Error trying to connect to socket: closing socket\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Error trying to connect to socket: closing socket\n"
     ]
    }
   ],
   "source": [
    "#Extracting the feautres & storing them in a list\n",
    "phish_features = []\n",
    "label = 1\n",
    "\n",
    "for i in range(0, 50):\n",
    "  url = phishurl['url'][i]\n",
    "  print(i)\n",
    "  phish_features.append(feature_Extraction(url,label))\n",
    "#converting the list to dataframe\n",
    "phishing = pd.DataFrame(phish_features, columns= feature_names)\n",
    "phishing.head()\n",
    "# Storing the extracted phishing URLs fatures to csv file\n",
    "phishing.to_csv('phish_features.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}